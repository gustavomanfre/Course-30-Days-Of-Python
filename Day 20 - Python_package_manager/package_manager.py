#üìö Ejercicio 1: Romeo y Julieta (Frecuencia de palabras)
#Objetivo: Descargar un libro de internet, limpiarlo de signos de puntuaci√≥n y contar qu√© palabras se repiten m√°s.

# 1. IMPORTACIONES
import requests  # Librer√≠a para hacer "llamadas" a internet (como abrir una web con c√≥digo).
import re        # Librer√≠a de "Expresiones Regulares" (para buscar patrones en texto).
from collections import Counter # Una herramienta especializada en contar elementos de una lista.

# 2. DEFINICI√ìN DE LA FUNCI√ìN
def contar_palabras_romeo():
    # Variable tipo string con la direcci√≥n web del archivo de texto.
    url = 'https://www.gutenberg.org/files/1112/1112.txt'
    
    # requests.get(url): Va a la direcci√≥n web y descarga el contenido.
    # .text: Extrae solo el contenido de texto de la respuesta (ignora encabezados t√©cnicos). Devuelve un <class 'str'>
    texto_bruto = requests.get(url).text
    
    # .lower(): Convierte TODO el texto a min√∫sculas.
    # Hacemos esto para que "Romeo" y "romeo" cuenten como la misma palabra.
    texto_limpio = texto_bruto.lower()
    
    # re.findall(patr√≥n, texto): Busca todas las coincidencias del patr√≥n en el texto.
    # r'\b[a-z]+\b': Es el patr√≥n m√°gico.
    #   \b: Inicio de palabra.
    #   [a-z]: Solo letras de la a a la z (ignora n√∫meros y puntos).
    #   +: Una o m√°s letras juntas.
    #   \b: Fin de palabra.
    # Resultado: Una lista gigante de palabras sueltas ['the', 'tragedy', 'of', 'romeo'...]
    lista_palabras = re.findall(r'\b[a-z]+\b', texto_limpio)
    
    # Counter(lista): Recorre la lista y crea un diccionario contando repeticiones.
    # Ejemplo interno: {'the': 1500, 'romeo': 300, ...}
    contador = Counter(lista_palabras)
    
    # .most_common(10): Devuelve las 10 palabras con el n√∫mero m√°s alto.
    top_10 = contador.most_common(10)
    
    return top_10

# 3. EJECUCI√ìN
# Llamamos a la funci√≥n e imprimimos el resultado.
print("Las 10 palabras m√°s frecuentes en Romeo y Julieta son:")
print(contar_palabras_romeo())

#üêà Ejercicio 2: API de Gatos (Estad√≠sticas)
#Objetivo: Convertir datos de texto (ej: "3 - 5 kgs") en n√∫meros reales para calcular promedios.

import requests    # Para descargar los datos de la API.
import statistics  # Librer√≠a matem√°tica para calcular media, mediana y desviaci√≥n est√°ndar.

def estadisticas_gatos():
    url = 'https://api.thecatapi.com/v1/breeds'
    
    # .json(): Convierte la respuesta de texto (formato JSON) en una lista de diccionarios de Python.
    # Ahora 'lista_gatos' es una lista donde cada elemento es un diccionario con datos de una raza.
    lista_gatos = requests.get(url).json() # Devuelve un <class 'list'> o una lista de diccionarios.
    # Ejemplo del contenido de lista_gatos[0]:
    # {
    #   'weight': {'imperial': '7 - 10', 'metric': '3 - 5'},
    #   'life_span': '12 - 15',
    #   'name': 'Abyssinian',
    #   ...
    # } 
    
    # Listas vac√≠as donde iremos guardando los n√∫meros limpios para calcular despu√©s.
    pesos_metricos = []
    vidas_anios = []

    # Bucle 'for': Recorre cada raza de gato en la lista descargada.
    for gato in lista_gatos:
        # --- PROCESAMIENTO DEL PESO ---
        # Accedemos al diccionario 'weight' y luego a la clave 'metric'.
        # El valor es un texto tipo "3 - 5".
        # gato es un diccionario con datos de UNA raza espec√≠fica.
        # Un ejemplo de un gato seria: {'weight': {'imperial': '7 - 10', 'metric': '3 - 5'}, life_span': '12 - 15', ...}
        #Entonces lista_gatos es una lista de esos diccionarios.
        #Denttro weight hay otro diccionario con imperial y metric. Para acceder a metric hacemos gato['weight']['metric']
        texto_peso = gato['weight']['metric']
        
        # .split(' - '): Corta el texto donde haya un guion.
        # Convierte "3 - 5" en una lista ["3", "5"].
        partes_peso = texto_peso.split(' - ')
        
        # float(): Convierte el texto "3" en el n√∫mero decimal 3.0.
        # Calculamos el promedio entre el m√≠nimo y m√°ximo de ESE gato espec√≠fico.
        # (3 + 5) / 2 = 4.0
        # Usamos [-1] y [0] por seguridad (por si solo viene un n√∫mero).
        peso_promedio_raza = (float(partes_peso[0]) + float(partes_peso[-1])) / 2
        
        # .append(): Agrega este n√∫mero a nuestra lista general de pesos.
        pesos_metricos.append(peso_promedio_raza)

        # --- PROCESAMIENTO DE VIDA √öTIL ---
        # El dato 'life_span' viene como "12 - 15". Hacemos lo mismo.
        texto_vida = gato['life_span']
        partes_vida = texto_vida.split(' - ')
        
        # Calculamos promedio de vida para esta raza.
        vida_promedio_raza = (float(partes_vida[0]) + float(partes_vida[-1])) / 2
        vidas_anios.append(vida_promedio_raza)

    # Funci√≥n auxiliar para imprimir bonito (evita repetir print 10 veces).
    def mostrar_datos(nombre_dato, lista_datos):
        print(f"\n--- Estad√≠sticas de {nombre_dato} ---")
        print(f"M√≠nimo: {min(lista_datos)}") # min(): Busca el valor m√°s peque√±o.
        print(f"M√°ximo: {max(lista_datos)}") # max(): Busca el valor m√°s grande.
        print(f"Media:  {statistics.mean(lista_datos):.2f}") # mean(): Promedio aritm√©tico.
        print(f"Mediana:{statistics.median(lista_datos)}")   # median(): El valor justo en el medio.
        print(f"Desviaci√≥n Est√°ndar: {statistics.stdev(lista_datos):.2f}") # stdev(): Qu√© tanto var√≠an los datos.

    # Llamamos a la funci√≥n auxiliar con nuestras listas llenas.
    mostrar_datos("Peso (kg)", pesos_metricos)
    mostrar_datos("Vida (a√±os)", vidas_anios)

# Ejecutamos la funci√≥n principal
estadisticas_gatos()


#üåç Ejercicio 3: API de Pa√≠ses (Ordenamiento y Conteo)

#Objetivo: Ordenar una lista de diccionarios (pa√≠ses) y extraer datos anidados (idiomas).

import requests
from collections import Counter

def analizar_paises():
    # URL de la API de pa√≠ses.
    url = 'https://restcountries.com/v2/all'
    paises = requests.get(url).json() # Descargamos y convertimos a lista de Python.
    # Paises es una lista donde cada elemento es un diccionario con datos de un pa√≠s.
    #Un ejemplo de la lista de diccionarios:
    #[
    #  {
    #    'name': 'Afghanistan',
    #    'area': 652230,
    #    'languages': [{'name': 'Pashto'}, {'name': 'Uzbek  '}, {'name': 'Turkmen'}],
    #    ...
    #  },....

    # --- PARTE A: 10 PA√çSES M√ÅS GRANDES ---
    
    # Paso 1: Filtrar.
    # Creamos una lista nueva solo con los pa√≠ses que tienen la clave 'area'.
    # Algunos pa√≠ses peque√±os o nuevos pueden no tener ese dato y romper√≠an el c√≥digo.
    #Aplicamos "list comprehension" para filtrar.
    #Una lista por comprensi√≥n tiene el siguiente formato:
        #[expresi√≥n for item in iterable if condici√≥n]
    #paises es una lista de diccionarios. Cada pais es un diccionario.
    #Si cada pais tiene la clave 'area', lo incluimos en la nueva lista.
    # Cada 'pais' se eval√∫a individualmente.
    # Si el diccionario tiene la clave 'area', se incluye en la nueva lista.
    paises_con_area = [pais for pais in paises if 'area' in pais]
    #paises_con_area contiene solo los pa√≠ses que tienen el dato 'area'.
    #Ejemplo: [{'name': 'Afghanistan', 'area': 652230, ...}, {'name': 'Albania', 'area': 28748, ...}, ...]
    
    # Paso 2: Ordenar (sorted).
    # key=lambda p: p['area']: Le dice a Python "Ordena bas√°ndote en el valor de 'area'".
    # reverse=True: Ordena de Mayor a Menor.
    # [:10]: "Slicing". Toma solo los primeros 10 elementos de la lista ordenada.
    
    # sorted(): tiene el siguiente formato: sorted(iterable, key=funci√≥n, reverse=bool)
    # iterable: es la lista que queremos ordenar.
    # funcion es una lambda con el siguiente formato: lambda par√°metro: expresi√≥n
    # La funci√≥n lambda NO recorre la lista.
    # sorted() recorre internamente la lista y le pasa cada elemento a la lambda.
    # Una funcion lambda funciona:
        # Parametro p: recibe un diccionario en el para√°metro p
        # La expresi√≥n p['area'] devuelve un n√∫mero (el √°rea del pa√≠s).
        # Ese n√∫mero se usa SOLO como criterio de comparaci√≥n para ordenar.
        # El resultado final sigue siendo una lista de diccionarios completos.
        #Ejemplo: De lo que recibe top_10_grandes es una lista de diccionarios ordenados por area. Ejemplo: [{'name': 'Russia', 'area': 17098242, ...}, {'name': 'Canada', 'area': 9984670, ...}, ...]
        # reverse=True hace que el orden sea de mayor a menor.
    top_10_grandes = sorted(paises_con_area, key=lambda p: p['area'], reverse=True)[:10]

    print("\n--- Los 10 pa√≠ses m√°s grandes ---")
    for pais in top_10_grandes:
        # Imprimimos nombre y √°rea formateada.
        print(f"{pais['name']}: {pais['area']} km¬≤")

    # --- PARTE B: IDIOMAS M√ÅS HABLADOS ---

    lista_todos_idiomas = []
    
    # Recorremos cada pa√≠s de la lista original.
    for pais in paises:
        # Verificamos si el diccionario pa√≠s tiene la clave 'languages'. Si tiene, procedemos.
        if 'languages' in pais: 
            # 'pais['languages']' es una lista de diccionarios: [{'name': 'Spanish'}, {'name': 'Guaran√≠'}]  idioma recibe un diccionario a la vez {'name': 'Spanish'}, {'name': 'Guaran√≠'}....
            for idioma in pais['languages']:
                #Agregamos a lista_todos_idiomas el nombre del idioma actual. Entonces lista_todos_idiomas es una lista con "Spanish", "English", etc.
                lista_todos_idiomas.append(idioma['name'])
    #Counter(lista): Cuenta cu√°ntas veces aparece cada elemento en la lista.
    # Usamos Counter de nuevo para contar cu√°ntas veces aparece "Spanish", "English", etc.
    #Counter devuelve un diccionario especial donde las claves son los idiomas y los valores son las cantidades.
    contador_idiomas = Counter(lista_todos_idiomas)
    
    print("\n--- Los 10 idiomas m√°s frecuentes ---")
    # Imprimimos los 10 m√°s comunes.
    # most_common(10): Devuelve una lista con las claves y valores de los 10 elementos con mayor valor en el contador.
    # Devuelve una lista de tuplas
    # Cada tupla es (idioma, cantidad)
    print(contador_idiomas.most_common(10))
    
    # --- PARTE C: TOTAL DE IDIOMAS ---
    # len(contador_idiomas): Cuenta cu√°ntas claves √öNICAS hay en el contador.
    print(f"\nN√∫mero total de idiomas √∫nicos en la API: {len(contador_idiomas)}")

analizar_paises()

# üï∑Ô∏è Ejercicio 4: Web Scraping (UCI Datasets)
# Objetivo:
# Leer una p√°gina web que NO es una API (es HTML pensado para humanos)
# y extraer informaci√≥n espec√≠fica utilizando BeautifulSoup.

import requests                      # Librer√≠a para hacer peticiones HTTP (GET, POST, etc.)
from bs4 import BeautifulSoup        # Herramienta para analizar (parsear) HTML y XML


def raspar_uci():
    """
    Esta funci√≥n:
    1) Descarga el HTML de la p√°gina del repositorio UCI
    2) Lo analiza con BeautifulSoup
    3) Busca los t√≠tulos de los datasets
    4) Imprime los primeros 20 encontrados
    """

    # URL del repositorio de Machine Learning de UCI.
    # Esta p√°gina devuelve HTML, NO JSON.
    url = 'https://archive.ics.uci.edu/datasets'
    
    # Hacemos una petici√≥n HTTP GET a la URL.
    # response es un objeto Response que contiene:
    # - status_code (200, 404, etc.)
    # - headers
    # - contenido de la p√°gina
    response = requests.get(url)

    # response.content contiene el cuerpo de la respuesta en formato binario (bytes).
    # BeautifulSoup puede trabajar directamente con este contenido.
    # Si quisi√©ramos texto plano, usar√≠amos response.text
    # Pero para HTML es mejor usar .content
    #content es un <class 'bytes'>
    content = response.content
    
    # Creamos el objeto BeautifulSoup (la "sopa"). beautifulSoup es una herramienta para analizar HTML.
    #beautifulSoup es una herramienta para analizar HTML. Proviene de la librer√≠a bs4.
    # bs4 no viene instalada por defecto con Python.
    # Se instala con: pip install beautifulsoup4
    # Par√°metros:
    # - content: El HTML crudo descargado de la web.
    # - 'html.parser': El motor que usar√° para interpretar el HTML.
    # BeautifulSoup:
    # - Toma el HTML crudo
    # - Lo convierte en un √°rbol de nodos (DOM)
    # - Permite buscar etiquetas, atributos y texto f√°cilmente
    #
    # 'html.parser' es el motor interno de Python para interpretar HTML.
    soup = BeautifulSoup(content, 'html.parser')
    
    # soup.find_all('h2'):
    # - Busca TODAS las etiquetas <h2> en el documento HTML, Solo las etiquetas <h2> no busca clases ni ids.
    # - Devuelve una lista de objetos h2 Tag de BeautifulSoup.
    #Devuelve una lista de objetos Tag
    #Cada Tag representa una etiqueta <h2> del HTML
    #Incluye:
        #la etiqueta <h2>
        #su texto interno
        #cualquier etiqueta anidada dentro (si existiera)
        #atributos (class, id, etc.)
    #
    # En la p√°gina actual de UCI, muchos nombres de datasets
    # est√°n dentro de etiquetas <h2>.
    #nombres_datasets es una lista de objetos Tag h2
    nombres_datasets = soup.find_all('h2')
    
    print("\n--- Datasets encontrados en UCI (Scraping) ---")
    
    # Recorremos solo los primeros 20 elementos tag h2 de la lista.
    # [:20] es slicing de listas y evita imprimir demasiados resultados.
    for titulo in nombres_datasets[:20]:
        
        # titulo es un objeto Tag de BeautifulSoup que representa:
        # <h2>Nombre del dataset</h2>
        #
        # titulo.text:
        # - Extrae solo el texto interno de la etiqueta
        #
        # .strip():
        # - Elimina espacios en blanco y saltos de l√≠nea al inicio y al final
        # 
        print(f"Dataset: {titulo.text.strip()}")


# NOTA IMPORTANTE:
# El Web Scraping es FR√ÅGIL.
# Si el sitio web cambia su estructura HTML
# (por ejemplo, reemplaza <h2> por <h3> o <div>),
# este c√≥digo dejar√° de funcionar correctamente.
# Esto es normal en scraping.
raspar_uci()
