<<<<<<< HEAD
=======
Para explicarte el Web Scraping de la mejor manera, voy a fusionar la claridad tÃ©cnica de un manual de programaciÃ³n con la narrativa de un libro de aventuras. Imagina que este es el capÃ­tulo central de un libro titulado "El Traductor de Internet".
ğŸ›ï¸ El Concepto: El Bibliotecario RobÃ³tico

Imagina que internet es una biblioteca con billones de pÃ¡ginas, pero estÃ¡n escritas en un lenguaje llamado HTML, que es una mezcla de contenido y etiquetas de diseÃ±o. Un humano puede leerlo visualmente, pero si quieres analizar miles de datos, tardarÃ­as aÃ±os.

El Web Scraping es la tÃ©cnica de construir un "Bibliotecario RobÃ³tico" que:

    Viaja a la direcciÃ³n (URL).
    Copia el cÃ³digo fuente.
    Filtra el ruido (colores, tamaÃ±os, botones) y se queda solo con la informaciÃ³n pura.

ğŸ› ï¸ Las Herramientas del Maestro

Para que tu robot funcione en Python, necesitas dos componentes que actÃºan como los sentidos del robot:

    Requests (El Tacto): Permite al robot "tocar" el servidor de la pÃ¡gina web y pedirle permiso para leer.
    BeautifulSoup (La Vista): Permite al robot "ver" y entender la estructura del cÃ³digo HTML, identificando dÃ³nde hay una tabla, un tÃ­tulo o un precio.

    1. Contexto general
        Cuando trabajamos con web scraping, el objetivo no es â€œverâ€ una pÃ¡gina web, sino leer su estructura.

    Una pÃ¡gina HTML estÃ¡ compuesta por:

        etiquetas (table, tr, td, etc.)
        atributos (id, class, cellpadding, etc.)
        texto interno
        
    BeautifulSoup actÃºa como un intÃ©rprete del HTML, permitiÃ©ndonos navegar esa estructura como si fuera un Ã¡rbol.

ğŸ’» El CÃ³digo Explicado "Desde Cero"

AquÃ­ tienes el proceso desglosado lÃ­nea por lÃ­nea, pensando en que es la primera vez que ves este lenguaje:
Python

import requests
from bs4 import BeautifulSoup

    ExplicaciÃ³n: Imagina que abres tu caja de herramientas. Con import, sacas el taladro (requests) y las pinzas de precisiÃ³n (BeautifulSoup). Sin estas lÃ­neas, Python no sabrÃ­a cÃ³mo conectarse a internet.

Python

url = 'https://archive.ics.uci.edu/ml/datasets.php'
response = requests.get(url)

    ExplicaciÃ³n: Primero definimos el destino. requests.get(url) es el robot saliendo de tu casa, caminando hasta la biblioteca y diciendo: "Hola, Â¿me das el contenido de esta pÃ¡gina?". La respuesta se guarda en una caja llamada response.

Python

status = response.status_code
print(status) # 200

    ExplicaciÃ³n: status_code es el pulgar del bibliotecario. Si te devuelve un 200, es un "pulgar arriba" (todo bien). Si es 404, es "no encontrÃ© el libro".

Python

content = response.content
soup = BeautifulSoup(content, 'html.parser')

    ExplicaciÃ³n: content es el cÃ³digo HTML bruto, un bloque de texto gigante y difÃ­cil de leer. Al pasarlo por BeautifulSoup con el "traductor" (html.parser), ese bloque se convierte en un mapa organizado que Python puede entender. A este mapa lo llamamos cariÃ±osamente soup (sopa).

Python

print(soup.title.get_text())

    ExplicaciÃ³n: AquÃ­ le das una orden directa: "Busca en el mapa la etiqueta llamada <title>, quÃ­tale las etiquetas y dime solo el texto que tiene dentro".

Python

tables = soup.find_all('table', {'cellpadding':'3'})
table = tables[0]

    ExplicaciÃ³n: Las pÃ¡ginas web tienen muchas tablas. Con find_all, le decimos al robot: "Busca todas las tablas que tengan una caracterÃ­stica (atributo) llamada cellpadding igual a 3". Como find_all devuelve una lista, usamos [0] para agarrar la primera que encontrÃ³.
        -soup es un objeto BeautifulSoup que contiene todo el HTML de la pÃ¡gina ya parseado.
        Pensalo como: â€œLa pÃ¡gina web convertida en un objeto que Python puede recorrerâ€
        -find_all() significa literalmente:
        â€œBuscÃ¡ TODOS los elementos que cumplan esta condiciÃ³nâ€
        En este caso:
            etiqueta: table
            atributo: cellpadding="3"
        TraducciÃ³n humana:
            â€œBuscÃ¡ todas las tablas que tengan el atributo cellpadding con valor 3â€
        Â¿QuÃ© devuelve find_all()?
            Siempre devuelve una lista, incluso si encuentra una sola tabla.
        Ejemplo conceptual:
            tables = [tabla1, tabla2, tabla3]
        Cada elemento de la lista es un objeto Tag, no texto plano.
        - Lista table = tables[0]
        las listas en Python empiezan en Ã­ndice 0
            [0] significa â€œla primera tabla encontradaâ€
        TraducciÃ³n mental:
            â€œDe todas las tablas encontradas, usÃ¡ la primeraâ€
        ğŸ“Œ En scraping esto es comÃºn cuando:
            sabÃ©s que la tabla que te interesa siempre aparece primero o ya verificaste la estructura del HTML
        La salida serÃ¡ algo parecido a esto (formato HTML):
            <table cellpadding="3">
            <tr>
                <td>Edad</td>
                <td>PaÃ­s</td>
                <td>Ciudad</td>
            </tr>
            <tr>
                <td>30</td>
                <td>Finland</td>
                <td>Helsinki</td>
            </tr>
            <tr>
                <td>28</td>
                <td>Finland</td>
                <td>Espoo</td>
            </tr>
            </table>

            âœ”ï¸ Es un objeto Tag que representa ese nodo del HTML
Python

for td in table.find('tr').find_all('td'):
    print(td.text)

    ExplicaciÃ³n: Esto es un Bucle (Loop). Imagina que el robot estÃ¡ frente a una fila de la tabla (tr). La orden es: "Por cada celda (td) que veas en esta fila, lee el texto y muÃ©stramelo en pantalla".

    5. table.find('tr')
    Â¿QuÃ© es tr?
        tr significa table row representa una fila de la tabla
    Entonces:
        table.find('tr')
    Significa:
        â€œDentro de esta tabla, buscÃ¡ la primera fila (tr)â€

    ğŸ“Œ find() devuelve solo el primer elemento que encuentra.

    6. find_all('td') sobre esa fila
        Â¿QuÃ© es td?
            td significa table data
        representa una celda de una tabla
        Entonces:   
            table.find('tr').find_all('td')
        
        TraducciÃ³n completa: â€œDentro de la primera fila de la tabla, buscÃ¡ todas las celdasâ€

    Esto devuelve: [td1, td2, td3, ...]

        Una lista de objetos td.

        7. El bucle for
            for td in table.find('tr').find_all('td'):

        Esto es un bucle de recorrido.

TraducciÃ³n humana:

â€œPara cada celda que exista en esta filaâ€¦â€

    Cada vuelta del bucle:
    td representa una celda distinta
    Forma correcta de pensarlo (mentalidad correcta ğŸ§ )

âŒ Pensamiento incorrecto:

    â€œEscribo cÃ³digo hasta que funcioneâ€
    âœ”ï¸ Pensamiento correcto:
    â€œEstoy recorriendo un Ã¡rbol HTML, nodo por nodoâ€
    HTML se piensa como:

    table
    â””â”€â”€ tr
        â”œâ”€â”€ td
        â”œâ”€â”€ td
        â””â”€â”€ td

Tu cÃ³digo sigue exactamente ese camino.

11. Resumen tipo libro ğŸ“˜
    find_all() â†’ busca muchos â†’ devuelve lista
    find() â†’ busca uno â†’ devuelve un elemento
    table â†’ objeto HTML
    tr â†’ fila
    td â†’ celda
    .text â†’ texto limpio
    for â†’ recorrido secuencial



_____________________________________________________________________________________________________________________________
Bienvenidos al CapÃ­tulo: Raspado Web (Web Scraping). Imagina que internet es una biblioteca infinita de libros, pero no tienes permitido llevarte los libros a casa. Solo puedes leerlos en las mesas. El Web Scraping es el arte de construir un pequeÃ±o robot que entra a esa biblioteca, lee la informaciÃ³n por ti y la anota en un cuaderno de forma organizada para que puedas usarla despuÃ©s.
ğŸ“– SecciÃ³n 1: La Caja de Herramientas

Para recolectar datos de un sitio web y guardarlos en tu computadora, necesitamos dos herramientas principales:

    Requests: Es el "mensajero". Se encarga de ir al sitio web, tocar la puerta y pedir el contenido de la pÃ¡gina.

    BeautifulSoup 4: Es el "traductor". El contenido que trae el mensajero suele ser cÃ³digo HTML desordenado. BeautifulSoup lo analiza y nos ayuda a encontrar exactamente lo que buscamos (como tÃ­tulos o tablas).

Para instalarlas, usamos estos comandos en la terminal (la consola de comandos):
Bash

pip install requests
pip install beautifulsoup4

ğŸ“– SecciÃ³n 2: AnÃ¡lisis del CÃ³digo Paso a Paso

A continuaciÃ³n, desglosamos el proceso de extracciÃ³n para alguien que nunca ha programado en Python.
Paso A: Tocar la puerta del sitio web
Python

import requests
from bs4 import BeautifulSoup

url = 'https://archive.ics.uci.edu/ml/datasets.php'
response = requests.get(url)
status = response.status_code
print(status) 

    import requests: Le decimos a Python: "Trae la herramienta para hacer llamadas a internet".

    from bs4 import BeautifulSoup: "Trae la herramienta para analizar cÃ³digo de pÃ¡ginas web".

    url = '...': Guardamos la direcciÃ³n de la pÃ¡gina en una "etiqueta" llamada url.

    response = requests.get(url): AquÃ­ el mensajero va a la URL y trae una "respuesta" que guardamos en la variable response.

    status = response.status_code: Preguntamos: "Â¿CÃ³mo saliÃ³ todo?". Si el cÃ³digo es 200, significa que la pÃ¡gina nos dejÃ³ entrar con Ã©xito.

Paso B: Traducir y leer el contenido

Una vez que tenemos la respuesta, el robot debe empezar a leer.
Python

content = response.content 
soup = BeautifulSoup(content, 'html.parser') 

    content = response.content: Extraemos todo el cÃ³digo "crudo" de la pÃ¡gina (el HTML).

    soup = BeautifulSoup(content, 'html.parser'): Creamos "la sopa". AquÃ­ Python organiza el desorden del cÃ³digo HTML para que podamos buscar etiquetas como si fuera un menÃº.

Paso C: Buscar datos especÃ­ficos

HTML funciona con etiquetas. Por ejemplo, el tÃ­tulo de una pÃ¡gina estÃ¡ entre <title> y </title>.
Python

print(soup.title.get_text()) 

    soup.title: Busca la etiqueta de tÃ­tulo.

    .get_text(): "Limpia" el cÃ³digo y quÃ©date solo con las letras.

Paso D: Extraer informaciÃ³n de una tabla

AquÃ­ es donde el robot se vuelve Ãºtil. Buscaremos una tabla especÃ­fica.
Python

tables = soup.find_all('table', {'cellpadding':'3'})
table = tables[0] 

for td in table.find('tr').find_all('td'):
    print(td.text)

    soup.find_all('table', ...): Le decimos: "Busca todas las tablas que tengan una caracterÃ­stica especial llamada cellpadding con valor 3".

    table = tables[0]: Como puede haber varias tablas, le decimos: "Dame la primera que encontraste" (en programaciÃ³n empezamos a contar desde 0).

    for td in ...: Esto es un Bucle. Le decimos: "Por cada celda (llamada td) que encuentres en la primera fila (tr), haz lo siguiente:".

    print(td.text): Imprime el texto que hay dentro de cada celda.
>>>>>>> 69388bf4d4d98e65262e3965c0283f912fd174ac
